{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "#\n",
    "# Copyright (C) The Adversarial Robustness Toolbox (ART) Authors 2020\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n",
    "# documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\n",
    "# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\n",
    "# persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the\n",
    "# Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\n",
    "# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n",
    "# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys\n",
    "from os.path import abspath\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow.keras.backend as k\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd, add_single_bd, insert_image\n",
    "from art.utils import load_mnist, preprocess, to_categorical\n",
    "from art.defences.trainer import AdversarialTrainerMadryPGD\n",
    "\n",
    "import import_ipynb\n",
    "from backdoor_attack_class import BackdoorAttack, CleanLabelBackdoorAttack\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_raw, y_raw), (x_raw_test, y_raw_test), min_, max_ = load_mnist(raw=True)\n",
    "\n",
    "# Random Selection:\n",
    "#n_train = np.shape(x_raw)[0]\n",
    "#num_selection = 7500\n",
    "#random_selection_indices = np.random.choice(n_train, num_selection)\n",
    "#x_raw = x_raw[random_selection_indices]\n",
    "#y_raw = y_raw[random_selection_indices]\n",
    "\n",
    "BACKDOOR_TYPE = \"pattern\" # one of ['pattern', 'pixel', 'image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(x_raw)\n",
    "def add_modification(x):\n",
    "        if BACKDOOR_TYPE == 'pattern':\n",
    "            return add_pattern_bd(x, pixel_value=max_val)\n",
    "        elif BACKDOOR_TYPE == 'pixel':\n",
    "            return add_single_bd(x, pixel_value=max_val) \n",
    "        elif BACKDOOR_TYPE == 'image':\n",
    "            return insert_image(x, backdoor_path='../utils/data/backdoors/alert.png', size=(10,10))\n",
    "        else:\n",
    "            raise(\"Unknown backdoor type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_dataset(dataset_clean, labels_clean, percent_poison, poison_func):\n",
    "    dataset_attacked = np.copy(dataset_clean)\n",
    "    labels_attacked = np.copy(labels_clean)\n",
    "    is_poison = np.zeros(np.shape(labels_attacked))\n",
    "    \n",
    "    sources = np.array([0])\n",
    "    targets = np.array([1])\n",
    "    for i, (src, tgt) in enumerate(zip(sources, targets)):\n",
    "        n_points_in_tgt = np.size(np.where(labels_clean == tgt))\n",
    "        num_poison = round((percent_poison * n_points_in_tgt) / (1 - percent_poison))\n",
    "        src_imgs = dataset_clean[labels_clean == src]\n",
    "\n",
    "        n_points_in_src = np.shape(src_imgs)[0]\n",
    "        indices_to_be_poisoned = np.random.choice(n_points_in_src, num_poison)\n",
    "\n",
    "        imgs_to_be_poisoned = np.copy(src_imgs[indices_to_be_poisoned])\n",
    "        backdoor_attack = BackdoorAttack(poison_func)\n",
    "        imgs_to_be_poisoned, poison_labels = backdoor_attack.poison(imgs_to_be_poisoned, attack_target_labels=np.ones(num_poison) * tgt)\n",
    "        dataset_attacked = np.append(dataset_attacked, imgs_to_be_poisoned, axis=0)\n",
    "        labels_attacked = np.append(labels_attacked, poison_labels, axis=0)\n",
    "        is_poison = np.append(is_poison, np.ones(num_poison))\n",
    "\n",
    "    is_poison = is_poison != 0\n",
    "\n",
    "    return is_poison, dataset_attacked, labels_attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poison training data\n",
    "percent_poison = .33\n",
    "(is_poison_train, x_poisoned_raw, y_poisoned_raw) = attack_dataset(x_raw, y_raw, percent_poison, add_modification)\n",
    "x_train, y_train = preprocess(x_poisoned_raw, y_poisoned_raw)\n",
    "# Add channel axis:\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "# Poison test data\n",
    "(is_poison_test, x_poisoned_raw_test, y_poisoned_raw_test) = attack_dataset(x_raw_test, y_raw_test, percent_poison, add_modification)\n",
    "x_test, y_test = preprocess(x_poisoned_raw_test, y_poisoned_raw_test)\n",
    "# Add channel axis:\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "# Shuffle training data\n",
    "n_train = np.shape(y_train)[0]\n",
    "shuffled_indices = np.arange(n_train)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "x_train = x_train[shuffled_indices]\n",
    "y_train = y_train[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_x_test = x_test[is_poison_test == 0]\n",
    "clean_y_test = y_test[is_poison_test == 0]\n",
    "\n",
    "clean_preds = np.argmax(classifier.predict(clean_x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(clean_y_test, axis=1))\n",
    "clean_total = clean_y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nClean test set accuracy: %.2f%%\" % (clean_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_x_test = x_test[is_poison_test]\n",
    "poison_y_test = y_test[is_poison_test]\n",
    "\n",
    "poison_preds = np.argmax(classifier.predict(poison_x_test), axis=1)\n",
    "poison_correct = np.sum(poison_preds == np.argmax(poison_y_test, axis=1))\n",
    "poison_total = poison_y_test.shape[0]\n",
    "\n",
    "poison_acc = poison_correct / poison_total\n",
    "print(\"\\n Effectiveness of poison: %.2f%%\" % (poison_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct = clean_correct + poison_correct\n",
    "total = clean_total + poison_total\n",
    "\n",
    "total_acc = total_correct / total\n",
    "print(\"\\n Overall test set accuracy: %.2f%%\" % (total_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extension\n",
    "\n",
    "x_train, y_train = preprocess(x_raw, y_raw)\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "x_test, y_test = preprocess(x_raw_test, y_raw_test)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "# Shuffle training data\n",
    "n_train = np.shape(y_train)[0]\n",
    "shuffled_indices = np.arange(n_train)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "x_train = x_train[shuffled_indices]\n",
    "y_train = y_train[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "\n",
    "def create_model():    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor = BackdoorAttack(add_pattern_bd)\n",
    "example_target = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "pdata, plabels = backdoor.poison(x_test, y=example_target)\n",
    "\n",
    "plt.imshow(pdata[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poison some percentage of all non-nines to nines\n",
    "targets = to_categorical([9], 10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(create_model())\n",
    "proxy = AdversarialTrainerMadryPGD(KerasClassifier(create_model()), nb_epochs=5, eps=0.15, eps_step=0.001)\n",
    "proxy.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = CleanLabelBackdoorAttack(backdoor=backdoor, proxy_classifier=proxy.get_classifier(),\n",
    "                                           target=targets, pp_poison=percent_poison, norm=2, eps=5,\n",
    "                                           eps_step=0.1, max_iter=200)\n",
    "pdata, plabels = attack.poison(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned = pdata[np.all(plabels == targets, axis=1)]\n",
    "poisoned_labels = plabels[np.all(plabels == targets, axis=1)]\n",
    "print(len(poisoned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(pdata, plabels, nb_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_preds = np.argmax(model.predict(x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(y_test, axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nClean test set accuracy: %.2f%%\" % (clean_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_target = np.logical_not(np.all(y_test == targets, axis=1))\n",
    "px_test, py_test = backdoor.poison(x_test[not_target], y_test[not_target])\n",
    "\n",
    "poison_preds = np.argmax(model.predict(px_test), axis=1)\n",
    "poison_correct = np.sum(poison_preds == np.argmax(py_test, axis=1))\n",
    "poison_total = py_test.shape[0]\n",
    "\n",
    "clean_correct = np.sum(poison_preds == np.argmax(y_test[not_target], axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nPoison test set accuracy: %.2f%%\" % (clean_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct = clean_correct + poison_correct\n",
    "total = clean_total + poison_total\n",
    "\n",
    "total_acc = total_correct / total\n",
    "print(\"\\n Overall test set accuracy: %.2f%%\" % (total_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
